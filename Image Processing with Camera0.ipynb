{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/influence.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers:\n",
    "        # Define initial bounding boxes for the objects to track\n",
    "        initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]\n",
    "\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers:\n",
    "        # Define initial bounding boxes for the objects to track\n",
    "        initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]\n",
    "\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 8.12\n",
      "FPS: 8.71\n",
      "FPS: 8.95\n",
      "FPS: 9.56\n",
      "FPS: 9.32\n",
      "FPS: 9.13\n",
      "FPS: 9.31\n",
      "FPS: 9.06\n",
      "FPS: 9.45\n",
      "FPS: 9.10\n",
      "FPS: 8.69\n",
      "FPS: 8.88\n",
      "FPS: 8.44\n",
      "FPS: 8.95\n",
      "FPS: 8.45\n",
      "FPS: 8.81\n",
      "FPS: 9.12\n",
      "FPS: 10.13\n",
      "FPS: 9.74\n",
      "FPS: 10.39\n",
      "FPS: 8.87\n",
      "FPS: 8.47\n",
      "FPS: 8.40\n",
      "FPS: 9.11\n",
      "FPS: 8.58\n",
      "FPS: 8.56\n",
      "FPS: 6.90\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Re-initialize trackers with the user-selected initial bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_bboxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Initialize trackers if not done yet\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trackers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43minitial_bboxes\u001b[49m) \u001b[38;5;241m==\u001b[39m num_objects:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# Initialize trackers with the provided bounding boxes\u001b[39;00m\n\u001b[0;32m     52\u001b[0m     trackers \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mTrackerMIL_create() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, bbox \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(initial_bboxes):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'initial_bboxes' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Use background subtraction for re-detection\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Re-initialize trackers with the largest contours\n",
    "        for i, contour in enumerate(contours[:num_objects]):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            trackers[i].init(frame, (x, y, w, h))\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initial_bboxes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Initialize trackers if not done yet\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trackers \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43minitial_bboxes\u001b[49m) \u001b[38;5;241m==\u001b[39m num_objects:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# Initialize trackers with the provided bounding boxes\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     trackers \u001b[38;5;241m=\u001b[39m [cv2\u001b[38;5;241m.\u001b[39mTrackerMIL_create() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, bbox \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(initial_bboxes):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'initial_bboxes' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Use background subtraction for re-detection\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Re-initialize trackers with the largest contours if a good match is found\n",
    "        for i, contour in enumerate(contours[:num_objects]):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Extract the region of interest (ROI) for feature matching\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert the ROI to grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Iterate through existing trackers and perform feature matching\n",
    "            for j, existing_tracker in enumerate(trackers):\n",
    "                _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                # Extract the existing object region for feature matching\n",
    "                existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                orb = cv2.ORB_create()\n",
    "                kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                # Match descriptors\n",
    "                matches = bf.match(des1, des2)\n",
    "\n",
    "                # Sort them in ascending order of distance\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                # Calculate the matching ratio\n",
    "                matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                if matching_ratio > feature_matching_threshold:\n",
    "                    trackers[i].init(frame, (x, y, w, h))\n",
    "                    break\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 106.72\n",
      "FPS: 98.58\n",
      "FPS: 111.98\n",
      "FPS: 110.48\n",
      "FPS: 107.78\n",
      "FPS: 105.90\n",
      "FPS: 111.73\n",
      "FPS: 110.52\n",
      "FPS: 108.99\n",
      "FPS: 102.25\n",
      "FPS: 101.70\n",
      "FPS: 113.80\n",
      "FPS: 104.98\n",
      "FPS: 103.81\n",
      "FPS: 106.27\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Use background subtraction for re-detection\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Re-initialize trackers with the largest contours if a good match is found\n",
    "        for i, contour in enumerate(contours[:num_objects]):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Extract the region of interest (ROI) for feature matching\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert the ROI to grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Iterate through existing trackers and perform feature matching\n",
    "            for j, existing_tracker in enumerate(trackers):\n",
    "                _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                # Extract the existing object region for feature matching\n",
    "                existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                orb = cv2.ORB_create()\n",
    "                kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                # Match descriptors\n",
    "                matches = bf.match(des1, des2)\n",
    "\n",
    "                # Sort them in ascending order of distance\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                # Calculate the matching ratio\n",
    "                matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                if matching_ratio > feature_matching_threshold:\n",
    "                    trackers[i].init(frame, (x, y, w, h))\n",
    "                    break\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 105.90\n",
      "FPS: 114.07\n",
      "FPS: 109.93\n",
      "FPS: 111.68\n",
      "FPS: 89.31\n",
      "FPS: 104.71\n",
      "FPS: 110.65\n",
      "FPS: 103.62\n",
      "FPS: 113.35\n",
      "FPS: 109.57\n",
      "FPS: 111.30\n",
      "FPS: 99.30\n",
      "FPS: 99.52\n",
      "FPS: 113.97\n",
      "FPS: 105.90\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "feature_matching_threshold = 0.7\n",
    "re_detection_interval = 100\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Use background subtraction for re-detection\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Re-initialize trackers with the largest contours if a good match is found\n",
    "        for i, contour in enumerate(contours[:num_objects]):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Extract the region of interest (ROI) for feature matching\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert the ROI to grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Iterate through existing trackers and perform feature matching\n",
    "            for j, existing_tracker in enumerate(trackers):\n",
    "                _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                # Extract the existing object region for feature matching\n",
    "                existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                orb = cv2.ORB_create()\n",
    "                kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                # Match descriptors\n",
    "                matches = bf.match(des1, des2)\n",
    "\n",
    "                # Sort them in ascending order of distance\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                # Calculate the matching ratio\n",
    "                matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                if matching_ratio > feature_matching_threshold:\n",
    "                    trackers[i].init(frame, (x, y, w, h))\n",
    "                    break\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "\n",
    "    # Termination conditions (add more as needed)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selecting_bbox' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 159\u001b[0m\n\u001b[0;32m    156\u001b[0m         current_bbox \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m# If adding a new object, draw the interactive bounding box\u001b[39;00m\n\u001b[1;32m--> 159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mselecting_bbox\u001b[49m:\n\u001b[0;32m    160\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mputText(frame, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelect a bounding box for the new object and press Enter\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m),\n\u001b[0;32m    161\u001b[0m                 cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.5\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    162\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMulti-object Tracking\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'selecting_bbox' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "feature_matching_threshold = 0.7\n",
    "re_detection_interval = 100\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize trackers if not done yet\n",
    "    if not trackers and len(initial_bboxes) == num_objects:\n",
    "        # Initialize trackers with the provided bounding boxes\n",
    "        trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            trackers[i].init(frame, bbox)\n",
    "\n",
    "    # Update trackers and draw bounding boxes\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "            # Display object ID labels\n",
    "            cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Object re-detection after a certain number of frames\n",
    "    frame_count_since_detection += 1\n",
    "    if frame_count_since_detection >= re_detection_interval:\n",
    "        # Reset the frame count\n",
    "        frame_count_since_detection = 0\n",
    "\n",
    "        # Use background subtraction for re-detection\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "        # Find contours in the mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Sort contours by area (largest first)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        # Re-initialize trackers with the largest contours if a good match is found\n",
    "        for i, contour in enumerate(contours[:num_objects]):\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Extract the region of interest (ROI) for feature matching\n",
    "            roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "            # Convert the ROI to grayscale\n",
    "            roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Iterate through existing trackers and perform feature matching\n",
    "            for j, existing_tracker in enumerate(trackers):\n",
    "                _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                # Extract the existing object region for feature matching\n",
    "                existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                orb = cv2.ORB_create()\n",
    "                kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                # Match descriptors\n",
    "                matches = bf.match(des1, des2)\n",
    "\n",
    "                # Sort them in ascending order of distance\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                # Calculate the matching ratio\n",
    "                matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                if matching_ratio > feature_matching_threshold:\n",
    "                    trackers[i].init(frame, (x, y, w, h))\n",
    "                    break\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    # Calculate and display FPS\n",
    "    fps_frame_count += 1\n",
    "    if time.time() - fps_start_time >= 1.0:\n",
    "        fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "        print(f\"FPS: {fps:.2f}\")\n",
    "        fps_frame_count = 0\n",
    "        fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "\n",
    "    # If adding a new object, draw the interactive bounding box\n",
    "    if selecting_bbox:\n",
    "        cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 1:\n",
    "            cv2.rectangle(frame, current_bbox[0], (x, y), (0, 255, 0), 2)\n",
    "            cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # If Enter key is pressed, add the new object\n",
    "        if key == 13:  # Enter key\n",
    "            selecting_bbox = False\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 156.38\n",
      "FPS: 199.08\n",
      "FPS: 121.79\n",
      "FPS: 102.70\n",
      "FPS: 108.49\n",
      "FPS: 102.99\n",
      "FPS: 98.25\n",
      "FPS: 96.89\n",
      "FPS: 92.66\n",
      "FPS: 94.84\n",
      "FPS: 105.61\n",
      "FPS: 95.33\n",
      "FPS: 99.62\n",
      "FPS: 92.40\n",
      "FPS: 104.48\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "feature_matching_threshold = 0.7\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False  # Add this line\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "\n",
    "    # If adding a new object, draw the interactive bounding box\n",
    "    if selecting_bbox and not paused:\n",
    "        cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 1:\n",
    "            cv2.rectangle(frame, current_bbox[0], (x, y), (0, 255, 0), 2)\n",
    "            cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # If Enter key is pressed, add the new object\n",
    "        if key == 13:  # Enter key\n",
    "            selecting_bbox = False\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 107.30\n",
      "FPS: 111.28\n",
      "FPS: 114.08\n",
      "FPS: 97.30\n",
      "FPS: 101.97\n",
      "FPS: 104.79\n",
      "FPS: 92.43\n",
      "FPS: 88.79\n",
      "FPS: 93.80\n",
      "FPS: 90.77\n",
      "FPS: 96.95\n",
      "FPS: 98.95\n",
      "FPS: 103.08\n",
      "FPS: 96.93\n",
      "FPS: 98.99\n",
      "FPS: 102.45\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False\n",
    "current_bbox = []\n",
    "\n",
    "# Interactive bounding box color\n",
    "bbox_color = (0, 255, 0)\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, bbox_color, 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "    elif key == ord('t'):  # Adjust feature matching threshold\n",
    "        print(\"Enter the new feature matching threshold (0 to 1): \")\n",
    "        feature_matching_threshold = float(input())\n",
    "    elif key == ord('i'):  # Adjust re-detection interval\n",
    "        print(\"Enter the new re-detection interval (number of frames): \")\n",
    "        re_detection_interval = int(input())\n",
    "\n",
    "    # If adding a new object, draw the interactive bounding box\n",
    "    if selecting_bbox and not paused:\n",
    "        cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 1:\n",
    "            cv2.rectangle(frame, current_bbox[0], (x, y), bbox_color, 2)\n",
    "            cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # If Enter key is pressed, add the new object\n",
    "        if key == 13:  # Enter key\n",
    "            selecting_bbox = False\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 96.99\n",
      "FPS: 72.80\n",
      "FPS: 89.18\n",
      "FPS: 95.84\n",
      "FPS: 87.49\n",
      "FPS: 88.86\n",
      "FPS: 85.81\n",
      "FPS: 101.89\n",
      "FPS: 89.71\n",
      "FPS: 88.78\n",
      "FPS: 95.68\n",
      "FPS: 92.95\n",
      "FPS: 87.99\n",
      "FPS: 87.75\n",
      "FPS: 78.88\n",
      "FPS: 98.65\n",
      "FPS: 88.65\n",
      "FPS: 76.99\n",
      "FPS: 87.59\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        selecting_bbox = False\n",
    "        current_bbox.append((x, y))\n",
    "        initial_bboxes.append(tuple(current_bbox))\n",
    "        current_bbox = []\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False\n",
    "current_bbox = []\n",
    "\n",
    "# Interactive bounding box color\n",
    "bbox_color = (0, 255, 0)\n",
    "\n",
    "# Status bar parameters\n",
    "status_bar_height = 30\n",
    "status_bar_color = (50, 50, 50)\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, bbox_color, 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        status_bar = np.zeros((status_bar_height, frame.shape[1], 3), dtype=np.uint8)\n",
    "        cv2.putText(status_bar, f'Feature Matching Threshold: {feature_matching_threshold:.2f} | Re-detection Interval: {re_detection_interval} frames',\n",
    "                    (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        frame_with_status_bar = np.vstack((frame, status_bar))\n",
    "        cv2.imshow('Multi-object Tracking', frame_with_status_bar)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "    elif key == ord('t'):  # Adjust feature matching threshold\n",
    "        print(\"Enter the new feature matching threshold (0 to 1): \")\n",
    "        feature_matching_threshold = max(0, min(1, float(input())))\n",
    "    elif key == ord('i'):  # Adjust re-detection interval\n",
    "        print(\"Enter the new re-detection interval (number of frames): \")\n",
    "        re_detection_interval = max(1, int(input()))\n",
    "\n",
    "    # If adding a new object, draw the interactive bounding box\n",
    "    if selecting_bbox and not paused:\n",
    "        cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 1:\n",
    "            cv2.rectangle(frame, current_bbox[0], (x, y), bbox_color, 2)\n",
    "            cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # If Enter key is pressed, add the new object\n",
    "        if key == 13:  # Enter key\n",
    "            selecting_bbox = False\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 87.23\n",
      "FPS: 82.99\n",
      "FPS: 78.59\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 67.28\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 86.37\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 76.22\n",
      "FPS: 93.80\n",
      "FPS: 75.55\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_MOUSEMOVE:\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m selecting_bbox:\n\u001b[1;32m---> 55\u001b[0m         \u001b[43mcurrent_bbox\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     56\u001b[0m         current_bbox[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m resizing_bbox:\n",
      "\u001b[1;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'init'\n> Overload resolution failed:\n>  - Can't parse 'boundingBox'. Expected sequence length 4, got 2\n>  - Can't parse 'boundingBox'. Expected sequence length 4, got 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 35\u001b[0m, in \u001b[0;36mselect_initial_bboxes\u001b[1;34m(event, x, y, flags, param)\u001b[0m\n\u001b[0;32m     33\u001b[0m         initial_bboxes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(current_bbox))\n\u001b[0;32m     34\u001b[0m         trackers\u001b[38;5;241m.\u001b[39mappend(cv2\u001b[38;5;241m.\u001b[39mTrackerMIL_create())\n\u001b[1;32m---> 35\u001b[0m         \u001b[43mtrackers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_bboxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m         current_bbox \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m event \u001b[38;5;241m==\u001b[39m cv2\u001b[38;5;241m.\u001b[39mEVENT_RBUTTONDOWN:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Check if the right-click is inside any existing bounding box for resizing\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) :-1: error: (-5:Bad argument) in function 'init'\n> Overload resolution failed:\n>  - Can't parse 'boundingBox'. Expected sequence length 4, got 2\n>  - Can't parse 'boundingBox'. Expected sequence length 4, got 2\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "Unknown C++ exception from OpenCV code",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Update trackers and draw bounding boxes\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tracker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trackers):\n\u001b[1;32m--> 109\u001b[0m     ret, bbox \u001b[38;5;241m=\u001b[39m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[0;32m    112\u001b[0m         p1 \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m(bbox[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(bbox[\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[1;31merror\u001b[0m: Unknown C++ exception from OpenCV code"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection and resizing)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox, resizing_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "        resizing_bbox = False\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        if selecting_bbox:\n",
    "            selecting_bbox = False\n",
    "            current_bbox.append((x, y))\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "            current_bbox = []\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        # Check if the right-click is inside any existing bounding box for resizing\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "                resizing_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                break\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONUP:\n",
    "        if resizing_bbox:\n",
    "            resizing_bbox = False\n",
    "            initial_bboxes[current_bbox[4]] = tuple(current_bbox[:4])\n",
    "            trackers[current_bbox[4]].init(frame, initial_bboxes[current_bbox[4]])\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if selecting_bbox:\n",
    "            current_bbox[1] = y\n",
    "            current_bbox[2] = x\n",
    "        elif resizing_bbox:\n",
    "            current_bbox[2] = x\n",
    "            current_bbox[3] = y\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False\n",
    "current_bbox = []\n",
    "resizing_bbox = False\n",
    "\n",
    "# Interactive bounding box color\n",
    "bbox_color = (0, 255, 0)\n",
    "resizing_bbox_color = (0, 0, 255)\n",
    "\n",
    "# Status bar parameters\n",
    "status_bar_height = 30\n",
    "status_bar_color = (50, 50, 50)\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, bbox_color, 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        status_bar = np.zeros((status_bar_height, frame.shape[1], 3), dtype=np.uint8)\n",
    "        cv2.putText(status_bar, f'Feature Matching Threshold: {feature_matching_threshold:.2f} | Re-detection Interval: {re_detection_interval} frames',\n",
    "                    (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        frame_with_status_bar = np.vstack((frame, status_bar))\n",
    "        cv2.imshow('Multi-object Tracking', frame_with_status_bar)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "    elif key == ord('t'):  # Adjust feature matching threshold\n",
    "        print(\"Enter the new feature matching threshold (0 to 1): \")\n",
    "        feature_matching_threshold = max(0, min(1, float(input())))\n",
    "    elif key == ord('i'):  # Adjust re-detection interval\n",
    "        print(\"Enter the new re-detection interval (number of frames): \")\n",
    "        re_detection_interval = max(1, int(input()))\n",
    "\n",
    "    # If adding a new object or resizing a bounding box, draw the interactive bounding box\n",
    "    if (selecting_bbox or resizing_bbox) and not paused:\n",
    "        if selecting_bbox:\n",
    "            cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "        elif resizing_bbox:\n",
    "            cv2.putText(frame, 'Resize the bounding box and release the right mouse button', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, resizing_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 2:\n",
    "            cv2.rectangle(frame, current_bbox[0], current_bbox[1], bbox_color, 2)\n",
    "        elif len(current_bbox) == 4:\n",
    "            cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), resizing_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 64.08\n",
      "FPS: 64.19\n",
      "FPS: 69.77\n",
      "FPS: 65.07\n",
      "FPS: 60.84\n",
      "FPS: 62.15\n",
      "FPS: 60.87\n",
      "FPS: 66.99\n",
      "FPS: 64.95\n",
      "FPS: 60.80\n",
      "FPS: 70.06\n",
      "FPS: 58.90\n",
      "FPS: 61.96\n",
      "FPS: 62.90\n",
      "FPS: 64.17\n",
      "FPS: 62.80\n",
      "FPS: 63.12\n",
      "FPS: 62.95\n",
      "FPS: 61.92\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection, resizing, and movement)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox, resizing_bbox, moving_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "        resizing_bbox = False\n",
    "        moving_bbox = False\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        if selecting_bbox:\n",
    "            selecting_bbox = False\n",
    "            current_bbox.append((x, y))\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "            current_bbox = []\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        # Check if the right-click is inside any existing bounding box for resizing or moving\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "                resizing_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                break\n",
    "            elif x_min - 10 <= x <= x_max + 10 and y_min - 10 <= y <= y_max + 10:\n",
    "                moving_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                offset_x = x - x_min\n",
    "                offset_y = y - y_min\n",
    "                break\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONUP:\n",
    "        if resizing_bbox:\n",
    "            resizing_bbox = False\n",
    "            initial_bboxes[current_bbox[4]] = tuple(current_bbox[:4])\n",
    "            trackers[current_bbox[4]].init(frame, initial_bboxes[current_bbox[4]])\n",
    "        elif moving_bbox:\n",
    "            moving_bbox = False\n",
    "            initial_bboxes[current_bbox[4]] = tuple(current_bbox[:4])\n",
    "            trackers[current_bbox[4]].init(frame, initial_bboxes[current_bbox[4]])\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if selecting_bbox:\n",
    "            current_bbox[1] = y\n",
    "            current_bbox[2] = x\n",
    "        elif resizing_bbox:\n",
    "            current_bbox[2] = x\n",
    "            current_bbox[3] = y\n",
    "        elif moving_bbox:\n",
    "            current_bbox[0] = x - offset_x\n",
    "            current_bbox[1] = y - offset_y\n",
    "            current_bbox[2] = x - offset_x + (current_bbox[2] - current_bbox[0])\n",
    "            current_bbox[3] = y - offset_y + (current_bbox[3] - current_bbox[1])\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False\n",
    "current_bbox = []\n",
    "resizing_bbox = False\n",
    "moving_bbox = False\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "\n",
    "# Interactive bounding box color\n",
    "bbox_color = (0, 255, 0)\n",
    "resizing_bbox_color = (0, 0, 255)\n",
    "moving_bbox_color = (255, 0, 0)\n",
    "\n",
    "# Status bar parameters\n",
    "status_bar_height = 30\n",
    "status_bar_color = (50, 50, 50)\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, bbox_color, 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        status_bar = np.zeros((status_bar_height, frame.shape[1], 3), dtype=np.uint8)\n",
    "        cv2.putText(status_bar, f'Feature Matching Threshold: {feature_matching_threshold:.2f} | Re-detection Interval: {re_detection_interval} frames',\n",
    "                    (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        frame_with_status_bar = np.vstack((frame, status_bar))\n",
    "        cv2.imshow('Multi-object Tracking', frame_with_status_bar)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "    elif key == ord('t'):  # Adjust feature matching threshold\n",
    "        print(\"Enter the new feature matching threshold (0 to 1): \")\n",
    "        feature_matching_threshold = max(0, min(1, float(input())))\n",
    "    elif key == ord('i'):  # Adjust re-detection interval\n",
    "        print(\"Enter the new re-detection interval (number of frames): \")\n",
    "        re_detection_interval = max(1, int(input()))\n",
    "\n",
    "    # If adding a new object, resizing a bounding box, or moving a bounding box, draw the interactive bounding box\n",
    "    if (selecting_bbox or resizing_bbox or moving_bbox) and not paused:\n",
    "        if selecting_bbox:\n",
    "            cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "        elif resizing_bbox:\n",
    "            cv2.putText(frame, 'Resize the bounding box and release the right mouse button', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, resizing_bbox_color, 2)\n",
    "        elif moving_bbox:\n",
    "            cv2.putText(frame, 'Move the bounding box and release the right mouse button', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, moving_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 2:\n",
    "            cv2.rectangle(frame, current_bbox[0], current_bbox[1], bbox_color, 2)\n",
    "        elif len(current_bbox) == 4:\n",
    "            if resizing_bbox:\n",
    "                cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), resizing_bbox_color, 2)\n",
    "            elif moving_bbox:\n",
    "                cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), moving_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPS: 72.06\n",
      "FPS: 87.98\n",
      "FPS: 84.83\n",
      "FPS: 84.66\n",
      "FPS: 81.72\n",
      "FPS: 84.68\n",
      "FPS: 80.71\n",
      "FPS: 79.88\n",
      "FPS: 72.73\n",
      "FPS: 83.08\n",
      "FPS: 89.81\n",
      "FPS: 84.71\n",
      "FPS: 82.75\n",
      "FPS: 87.96\n",
      "FPS: 89.85\n",
      "FPS: 93.48\n",
      "FPS: 77.89\n",
      "FPS: 88.41\n",
      "FPS: 90.47\n",
      "FPS: 83.26\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')  # Replace with the path to your video file\n",
    "\n",
    "# Number of objects to track\n",
    "num_objects = 2  # Adjust based on your application\n",
    "\n",
    "# Initialize trackers with an empty list\n",
    "trackers = []\n",
    "\n",
    "# Background subtractor for object re-detection\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=False)\n",
    "\n",
    "# Feature matching parameters\n",
    "feature_matching_threshold = 0.7\n",
    "\n",
    "# Callback function for mouse events (used for interactive bounding box selection, resizing, movement, and deletion)\n",
    "def select_initial_bboxes(event, x, y, flags, param):\n",
    "    global initial_bboxes, selecting_bbox, current_bbox, resizing_bbox, moving_bbox, deleting_bbox\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        selecting_bbox = True\n",
    "        current_bbox = [(x, y)]\n",
    "        resizing_bbox = False\n",
    "        moving_bbox = False\n",
    "        deleting_bbox = False\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        if selecting_bbox:\n",
    "            selecting_bbox = False\n",
    "            current_bbox.append((x, y))\n",
    "            initial_bboxes.append(tuple(current_bbox))\n",
    "            trackers.append(cv2.TrackerMIL_create())\n",
    "            trackers[-1].init(frame, initial_bboxes[-1])\n",
    "            current_bbox = []\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:\n",
    "        # Check if the right-click is inside any existing bounding box for resizing, moving, or deletion\n",
    "        for i, bbox in enumerate(initial_bboxes):\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "            if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "                resizing_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                break\n",
    "            elif x_min - 10 <= x <= x_max + 10 and y_min - 10 <= y <= y_max + 10:\n",
    "                moving_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                offset_x = x - x_min\n",
    "                offset_y = y - y_min\n",
    "                break\n",
    "            elif x_min - 20 <= x <= x_max + 20 and y_min - 20 <= y <= y_max + 20:\n",
    "                deleting_bbox = True\n",
    "                current_bbox = [x_min, y_min, x_max, y_max, i]\n",
    "                break\n",
    "\n",
    "    elif event == cv2.EVENT_RBUTTONUP:\n",
    "        if resizing_bbox:\n",
    "            resizing_bbox = False\n",
    "            initial_bboxes[current_bbox[4]] = tuple(current_bbox[:4])\n",
    "            trackers[current_bbox[4]].init(frame, initial_bboxes[current_bbox[4]])\n",
    "        elif moving_bbox:\n",
    "            moving_bbox = False\n",
    "            initial_bboxes[current_bbox[4]] = tuple(current_bbox[:4])\n",
    "            trackers[current_bbox[4]].init(frame, initial_bboxes[current_bbox[4]])\n",
    "        elif deleting_bbox:\n",
    "            deleting_bbox = False\n",
    "            initial_bboxes.pop(current_bbox[4])\n",
    "            trackers.pop(current_bbox[4])\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if selecting_bbox:\n",
    "            current_bbox[1] = y\n",
    "            current_bbox[2] = x\n",
    "        elif resizing_bbox:\n",
    "            current_bbox[2] = x\n",
    "            current_bbox[3] = y\n",
    "        elif moving_bbox:\n",
    "            current_bbox[0] = x - offset_x\n",
    "            current_bbox[1] = y - offset_y\n",
    "            current_bbox[2] = x - offset_x + (current_bbox[2] - current_bbox[0])\n",
    "            current_bbox[3] = y - offset_y + (current_bbox[3] - current_bbox[1])\n",
    "\n",
    "# Set up the window and callback\n",
    "cv2.namedWindow('Multi-object Tracking')\n",
    "cv2.setMouseCallback('Multi-object Tracking', select_initial_bboxes)\n",
    "\n",
    "# Variables for re-detection\n",
    "re_detection_interval = 100  # Number of frames before re-detection\n",
    "frame_count_since_detection = 0\n",
    "\n",
    "# Variables for performance monitoring\n",
    "fps_start_time = time.time()\n",
    "fps_frame_count = 0\n",
    "\n",
    "# Define initial bounding boxes for the objects to track\n",
    "initial_bboxes = []  # Add your initial bounding boxes during runtime\n",
    "\n",
    "# Adjustable parameters\n",
    "re_detection_interval = 100\n",
    "\n",
    "# Variables for video control\n",
    "paused = False\n",
    "selecting_bbox = False\n",
    "current_bbox = []\n",
    "resizing_bbox = False\n",
    "moving_bbox = False\n",
    "deleting_bbox = False\n",
    "offset_x = 0\n",
    "offset_y = 0\n",
    "\n",
    "# Interactive bounding box color\n",
    "bbox_color = (0, 255, 0)\n",
    "resizing_bbox_color = (0, 0, 255)\n",
    "moving_bbox_color = (255, 0, 0)\n",
    "deleting_bbox_color = (0, 0, 255)\n",
    "\n",
    "# Status bar parameters\n",
    "status_bar_height = 30\n",
    "status_bar_color = (50, 50, 50)\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Initialize trackers if not done yet\n",
    "        if not trackers and len(initial_bboxes) == num_objects:\n",
    "            # Initialize trackers with the provided bounding boxes\n",
    "            trackers = [cv2.TrackerMIL_create() for _ in range(num_objects)]\n",
    "            for i, bbox in enumerate(initial_bboxes):\n",
    "                trackers[i].init(frame, bbox)\n",
    "\n",
    "        # Update trackers and draw bounding boxes\n",
    "        for i, tracker in enumerate(trackers):\n",
    "            ret, bbox = tracker.update(frame)\n",
    "\n",
    "            if ret:\n",
    "                p1 = (int(bbox[0]), int(bbox[1]))\n",
    "                p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "                cv2.rectangle(frame, p1, p2, bbox_color, 2)\n",
    "\n",
    "                # Display object ID labels\n",
    "                cv2.putText(frame, f'Object {i + 1}', (p1[0], p1[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "\n",
    "        # Object re-detection after a certain number of frames\n",
    "        frame_count_since_detection += 1\n",
    "        if frame_count_since_detection >= re_detection_interval:\n",
    "            # Reset the frame count\n",
    "            frame_count_since_detection = 0\n",
    "\n",
    "            # Use background subtraction for re-detection\n",
    "            fg_mask = bg_subtractor.apply(frame)\n",
    "            fg_mask[fg_mask < 255] = 0  # Threshold the mask\n",
    "\n",
    "            # Find contours in the mask\n",
    "            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "            # Sort contours by area (largest first)\n",
    "            contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "            # Re-initialize trackers with the largest contours if a good match is found\n",
    "            for i, contour in enumerate(contours[:num_objects]):\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "                # Extract the region of interest (ROI) for feature matching\n",
    "                roi = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Convert the ROI to grayscale\n",
    "                roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Iterate through existing trackers and perform feature matching\n",
    "                for j, existing_tracker in enumerate(trackers):\n",
    "                    _, existing_bbox = existing_tracker.update(frame)\n",
    "\n",
    "                    # Extract the existing object region for feature matching\n",
    "                    existing_x, existing_y, existing_w, existing_h = map(int, existing_bbox)\n",
    "                    existing_roi = frame[existing_y:existing_y + existing_h, existing_x:existing_x + existing_w]\n",
    "                    existing_roi_gray = cv2.cvtColor(existing_roi, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                    # Use ORB (Oriented FAST and Rotated BRIEF) for feature matching\n",
    "                    orb = cv2.ORB_create()\n",
    "                    kp1, des1 = orb.detectAndCompute(existing_roi_gray, None)\n",
    "                    kp2, des2 = orb.detectAndCompute(roi_gray, None)\n",
    "\n",
    "                    # Create a BFMatcher (Brute-Force Matcher) object\n",
    "                    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "                    # Match descriptors\n",
    "                    matches = bf.match(des1, des2)\n",
    "\n",
    "                    # Sort them in ascending order of distance\n",
    "                    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                    # Calculate the matching ratio\n",
    "                    matching_ratio = len(matches) / len(kp1)\n",
    "\n",
    "                    # If a good match is found, re-initialize the tracker with the new bounding box\n",
    "                    if matching_ratio > feature_matching_threshold:\n",
    "                        trackers[i].init(frame, (x, y, w, h))\n",
    "                        break\n",
    "\n",
    "        # Display the frame with bounding boxes\n",
    "        status_bar = np.zeros((status_bar_height, frame.shape[1], 3), dtype=np.uint8)\n",
    "        cv2.putText(status_bar, f'Feature Matching Threshold: {feature_matching_threshold:.2f} | Re-detection Interval: {re_detection_interval} frames | Tracked Objects: {len(trackers)}',\n",
    "                    (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        frame_with_status_bar = np.vstack((frame, status_bar))\n",
    "        cv2.imshow('Multi-object Tracking', frame_with_status_bar)\n",
    "\n",
    "        # Calculate and display FPS\n",
    "        fps_frame_count += 1\n",
    "        if time.time() - fps_start_time >= 1.0:\n",
    "            fps = fps_frame_count / (time.time() - fps_start_time)\n",
    "            print(f\"FPS: {fps:.2f}\")\n",
    "            fps_frame_count = 0\n",
    "            fps_start_time = time.time()\n",
    "\n",
    "    # Check for keypress events\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):  # Remove the last tracked object\n",
    "        if len(trackers) > 0:\n",
    "            trackers.pop()\n",
    "    elif key == ord('a'):  # Add a new object\n",
    "        if len(trackers) < num_objects:\n",
    "            selecting_bbox = True\n",
    "            current_bbox = []\n",
    "    elif key == ord('p'):  # Pause or resume the video\n",
    "        paused = not paused\n",
    "        print(\"Video Paused\" if paused else \"Video Resumed\")\n",
    "    elif key == ord('t'):  # Adjust feature matching threshold\n",
    "        print(\"Enter the new feature matching threshold (0 to 1): \")\n",
    "        feature_matching_threshold = max(0, min(1, float(input())))\n",
    "    elif key == ord('i'):  # Adjust re-detection interval\n",
    "        print(\"Enter the new re-detection interval (number of frames): \")\n",
    "        re_detection_interval = max(1, int(input()))\n",
    "    elif key == ord('d'):  # Delete a bounding box\n",
    "        if len(trackers) > 0:\n",
    "            deleting_bbox = True\n",
    "            current_bbox = []\n",
    "\n",
    "    # If adding a new object, resizing a bounding box, moving a bounding box, or deleting a bounding box, draw the interactive bounding box\n",
    "    if (selecting_bbox or resizing_bbox or moving_bbox or deleting_bbox) and not paused:\n",
    "        if selecting_bbox:\n",
    "            cv2.putText(frame, 'Select a bounding box for the new object and press Enter', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, bbox_color, 2)\n",
    "        elif resizing_bbox:\n",
    "            cv2.putText(frame, 'Resize the bounding box and release the right mouse button', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, resizing_bbox_color, 2)\n",
    "        elif moving_bbox:\n",
    "            cv2.putText(frame, 'Move the bounding box and release the right mouse button', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, moving_bbox_color, 2)\n",
    "        elif deleting_bbox:\n",
    "            cv2.putText(frame, 'Right-click inside a bounding box to delete it', (10, 30),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, deleting_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "        # Draw the interactive bounding box\n",
    "        if len(current_bbox) == 2:\n",
    "            cv2.rectangle(frame, current_bbox[0], current_bbox[1], bbox_color, 2)\n",
    "        elif len(current_bbox) == 4:\n",
    "            if resizing_bbox:\n",
    "                cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), resizing_bbox_color, 2)\n",
    "            elif moving_bbox:\n",
    "                cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), moving_bbox_color, 2)\n",
    "            elif deleting_bbox:\n",
    "                cv2.rectangle(frame, (current_bbox[0], current_bbox[1]), (current_bbox[2], current_bbox[3]), deleting_bbox_color, 2)\n",
    "\n",
    "        cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerKCF_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerKCF_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_objects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerKCF_create\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerKCF_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple KCF trackers\n",
    "num_objects = 2\n",
    "trackers = [cv2.TrackerKCF_create() for _ in range(num_objects)]\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for i, bbox in enumerate(initial_bboxes):\n",
    "    trackers[i].init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'MultiTracker_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple MOSSE trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiTracker_create\u001b[49m()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'MultiTracker_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple MOSSE trackers\n",
    "num_objects = 2\n",
    "trackers = cv2.MultiTracker_create()\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for bbox in initial_bboxes:\n",
    "    trackers.add(cv2.TrackerMOSSE_create(), frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Update all trackers on the current frame\n",
    "    ret, bboxes = trackers.update(frame)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        p1 = (int(bbox[0]), int(bbox[1]))\n",
    "        p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "        cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerMOSSE_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple MOSSE trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerMOSSE_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_objects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple MOSSE trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerMOSSE_create\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerMOSSE_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple MOSSE trackers\n",
    "num_objects = 2\n",
    "trackers = [cv2.TrackerMOSSE_create() for _ in range(num_objects)]\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "current_bboxes = initial_bboxes.copy()\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for i, bbox in enumerate(initial_bboxes):\n",
    "    trackers[i].init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            current_bboxes[i] = bbox\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'Tracker_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracker_create\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mKCF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_objects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracker_create\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKCF\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'Tracker_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple KCF trackers\n",
    "num_objects = 2\n",
    "trackers = [cv2.Tracker_create('KCF') for _ in range(num_objects)]\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "current_bboxes = initial_bboxes.copy()\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for i, bbox in enumerate(initial_bboxes):\n",
    "    trackers[i].init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            current_bboxes[i] = bbox\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerKCF_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerKCF_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_objects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple KCF trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerKCF_create\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerKCF_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple KCF trackers\n",
    "num_objects = 2\n",
    "trackers = [cv2.TrackerKCF_create() for _ in range(num_objects)]\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "current_bboxes = initial_bboxes.copy()\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for i, bbox in enumerate(initial_bboxes):\n",
    "    trackers[i].init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            current_bboxes[i] = bbox\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'TrackerMOSSE_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple MOSSE trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerMOSSE_create\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_objects\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 11\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create multiple MOSSE trackers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_objects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 11\u001b[0m trackers \u001b[38;5;241m=\u001b[39m [\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrackerMOSSE_create\u001b[49m() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_objects)]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize bounding boxes for each object (you can modify this based on your needs)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m initial_bboxes \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m), (\u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Format: (x, y, width, height)\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'TrackerMOSSE_create'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Initialize video capture (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('videos/Start your IT Journey in 2023 RIGHT NOW.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Create multiple MOSSE trackers\n",
    "num_objects = 2\n",
    "trackers = [cv2.TrackerMOSSE_create() for _ in range(num_objects)]\n",
    "\n",
    "# Initialize bounding boxes for each object (you can modify this based on your needs)\n",
    "initial_bboxes = [(100, 100, 50, 50), (200, 200, 50, 50)]  # Format: (x, y, width, height)\n",
    "current_bboxes = initial_bboxes.copy()\n",
    "\n",
    "# Initialize trackers with the initial bounding boxes\n",
    "for i, bbox in enumerate(initial_bboxes):\n",
    "    trackers[i].init(frame, bbox)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    for i, tracker in enumerate(trackers):\n",
    "        ret, bbox = tracker.update(frame)\n",
    "\n",
    "        if ret:\n",
    "            current_bboxes[i] = bbox\n",
    "            p1 = (int(bbox[0]), int(bbox[1]))\n",
    "            p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
    "            cv2.rectangle(frame, p1, p2, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('Multi-object Tracking', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
